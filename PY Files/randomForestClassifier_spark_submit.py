# -*- coding: utf-8 -*-
"""RFClassifierProjectAlgo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hKB84NG30JcebiIe6j1FLk5CnNTWlD_f

## Overview

This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.

This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.sql.functions import regexp_extract, col, when
from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator
from pyspark.ml import Pipeline
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit
import time

from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# True when to create Python soure code to run with spark-submit
IS_SPARK_SUBMIT_CLI = True

if IS_SPARK_SUBMIT_CLI:
    sc = SparkContext.getOrCreate()
    spark = SparkSession(sc)

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# File location and type
file_location = "/user/apang5/used_cars_data.csv"
file_type = "csv"

# CSV options
infer_schema = "true"
first_row_is_header = "true"
delimiter = ","

# The applied options are for CSV files. For other file types, these will be ignored.
df = spark.read.format(file_type) \
  .option("inferSchema", infer_schema) \
  .option("header", first_row_is_header) \
  .option("sep", delimiter) \
  .load(file_location)

df.show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Load the CSV with safe parsing options
df = spark.read.format(file_type) \
 .option("header", "true") \
 .option("inferSchema", "true") \
 .option("sep", ",") \
 .option("quote", "\"") \
 .option("escape", "\"") \
 .option("multiLine", "true") \
 .option("mode", "PERMISSIVE") \
 .load(file_location)

df.printSchema()
df.show(5, truncate=False)

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# -----------------------------------------
# 1. Data Preparation (cleaning, as before)
# -----------------------------------------
data = df.select("city_fuel_economy", "highway_fuel_economy", "daysonmarket",
                 "engine_displacement", "horsepower", "mileage", "seller_rating",
                 "year", "price", "engine_cylinders", "torque", "power",
                 "front_legroom", "wheelbase", "width", "body_type", "has_accidents",
                 'fuel_type', 'transmission', 'make_name', 'model_name', 'exterior_color',
                 'interior_color', 'dealer_zip', 'franchise_make', 'wheel_system')

# Cast numeric columns properly
data = data.withColumn("city_fuel_economy", col("city_fuel_economy").cast("double")) \
           .withColumn("highway_fuel_economy", col("highway_fuel_economy").cast("double")) \
           .withColumn("daysonmarket", col("daysonmarket").cast("int")) \
           .withColumn("engine_displacement", col("engine_displacement").cast("double")) \
           .withColumn("horsepower", col("horsepower").cast("double")) \
           .withColumn("mileage", col("mileage").cast("double")) \
           .withColumn("seller_rating", col("seller_rating").cast("double")) \
           .withColumn("year", col("year").cast("int")) \
           .withColumn("price", col("price").cast("double")) \
           .withColumn("engine_cylinders", regexp_extract("engine_cylinders", "(\\d+)", 1).cast("double")) \
           .withColumn("torque", regexp_extract("torque", "(\\d+)", 1).cast("double")) \
           .withColumn("power", regexp_extract("power", "(\\d+)", 1).cast("double"))

for col_name in ["front_legroom", "wheelbase", "width"]:
    data = data.withColumn(col_name, regexp_extract(col_name, "(\\d+\\.\\d+)", 1).cast("double"))

data = data.withColumn("has_accidents", col("has_accidents").cast("int"))
data = data.dropna()
data.groupBy("has_accidents").count().show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# -----------------------------------------
# Feature Preparation
# -----------------------------------------
feature_cols = [
    'city_fuel_economy', 'highway_fuel_economy', 'engine_displacement',
    'horsepower', 'seller_rating', 'year', 'mileage',
    'engine_cylinders', 'torque', 'power', 'front_legroom', 'wheelbase', 'width'
]

numeric_features = [
    'city_fuel_economy', 'highway_fuel_economy', 'engine_displacement',
    'horsepower', 'seller_rating', 'year', 'mileage',
    'engine_cylinders', 'torque', 'power', 'front_legroom', 'wheelbase', 'width'
]

categorical_features = [
    'body_type', 'fuel_type', 'transmission', 'make_name', 'model_name', 'exterior_color',
    'interior_color', 'dealer_zip', 'franchise_make', 'wheel_system'
]

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# === Index + One-Hot Encode categorical features ===
indexers = [StringIndexer(inputCol=col, outputCol=f"{col}_idx", handleInvalid="keep") for col in categorical_features]
encoders = [OneHotEncoder(inputCol=f"{col}_idx", outputCol=f"{col}_vec") for col in categorical_features]
encoded_features = [f"{col}_vec" for col in categorical_features]

# === Assemble and scale numeric features ===
num_assembler = VectorAssembler(inputCols=numeric_features, outputCol="num_features")
scaler = MinMaxScaler(inputCol="num_features", outputCol="scaled_features")

# === Final feature assembler ===
final_assembler = VectorAssembler(inputCols=encoded_features + ["scaled_features"], outputCol="features")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

splits = data.randomSplit([0.7, 0.3])
train = splits[0]
test = splits[1]
train_rows = train.count()
test_rows = test.count()
print("Training Rows:", train_rows, " Testing Rows:", test_rows)

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# === Define model ===
rf = RandomForestClassifier(featuresCol="features", labelCol="has_accidents", seed=42, numTrees=100, maxDepth=5)

# === Build pipeline ===
pipeline_rf = Pipeline(stages=indexers + encoders + [num_assembler, scaler, final_assembler, rf])

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Create Evaluate Objects For Model Measurement Performance
evaluator_auc = BinaryClassificationEvaluator(labelCol="has_accidents", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
evaluator_accuracy = MulticlassClassificationEvaluator(
    labelCol="has_accidents",
    predictionCol="prediction",
    metricName="accuracy"
)
evaluator_precision = MulticlassClassificationEvaluator(
    labelCol="has_accidents",
    predictionCol="prediction",
    metricName="weightedPrecision"
)
evaluator_recall = MulticlassClassificationEvaluator(
    labelCol="has_accidents",
    predictionCol="prediction",
    metricName="weightedRecall"
)
evaluator_f1 = MulticlassClassificationEvaluator(
    labelCol="has_accidents",
    predictionCol="prediction",
    metricName="f1"
)

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Set up hyperparameter grid (optional but useful)
paramGrid = (ParamGridBuilder()
    .addGrid(rf.numTrees, [50, 100])
    .addGrid(rf.maxDepth, [5, 10])
    .build())

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Define & Create CrossValidator
cv = CrossValidator(estimator=pipeline_rf,
                       estimatorParamMaps=paramGrid,
                       evaluator=evaluator_auc, numFolds=3)

# Train model using Cross Validation
cv_start = time.time()
cvModel = cv.fit(train)
cv_end = time.time()

cv_time = cv_end - cv_start

# Make predictions
cv_predictions = cvModel.transform(test)

# Evaluate
cv_auc = evaluator_auc.evaluate(cv_predictions)
cv_accuracy = evaluator_accuracy.evaluate(cv_predictions)
cv_precision = evaluator_precision.evaluate(cv_predictions)
cv_recall = evaluator_recall.evaluate(cv_predictions)
cv_f1 = evaluator_f1.evaluate(cv_predictions)

print(f"Cross-Validated AUC (RandomForest Regression): {cv_auc:.4f}")
print(f"Cross-Validated Accuracy (RandomForest Regression): {cv_accuracy:.4f}")
print(f"Cross-Validated Precision (RandomForest Regression): {cv_precision:.4f}")
print(f"Cross-Validated Recall (RandomForest Regression): {cv_recall:.4f}")
print(f"Cross-Validated F1 (RandomForest Regression): {cv_f1:.4f}")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# 5. Define & Create TrainValidationSplit
tvs = TrainValidationSplit(estimator=pipeline_rf,
                           estimatorParamMaps=paramGrid,
                           evaluator=evaluator_auc,
                           trainRatio=0.8)

# 6. Train model using Train Validation
tvs_start = time.time()
tvsModel = tvs.fit(train)
tvs_end = time.time()

tvs_time = tvs_end - tvs_start

# 7. Make predictions
tvs_predictions = tvsModel.transform(test)

# 8. Evaluate
tvs_auc = evaluator_auc.evaluate(tvs_predictions)
tvs_accuracy = evaluator_accuracy.evaluate(tvs_predictions)
tvs_precision = evaluator_precision.evaluate(tvs_predictions)
tvs_recall = evaluator_recall.evaluate(tvs_predictions)
tvs_f1 = evaluator_f1.evaluate(tvs_predictions)

print(f"Train Validation Split AUC (RandomForest Regression): {tvs_auc:.4f}")
print(f"Train Validation Split Accuracy (RandomForest Regression): {tvs_accuracy:.4f}")
print(f"Train Validation Split Precision (RandomForest Regression): {tvs_precision:.4f}")
print(f"Train Validation Split Recall (RandomForest Regression): {tvs_recall:.4f}")
print(f"Train Validation Split F1 (RandomForest Regression): {tvs_f1:.4f}")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# --- Summary of All Results ---
print(f"\n--- Summary of All Results ---")
print(f"Training Rows: {train_rows:,}\nTesting Rows: {test_rows:,}")

print(f"\n--- Summary of Cross-Validation Results ---")
print(f"CV AUC: {cv_auc:.4f}")
print(f"CV Accuracy: {cv_accuracy:.4f}")
print(f"CV Precision: {cv_precision:.4f}")
print(f"CV Recall: {cv_recall:.4f}")
print(f"CV F1: {cv_f1:.4f}")
print(f"CV Time: {cv_time:.2f} seconds")

print(f"\n--- Summary of Train-Validation-Split Results ---")
print(f"TVS AUC: {tvs_auc:.4f}")
print(f"TVS Accuracy: {tvs_accuracy:.4f}")
print(f"TVS Precision: {tvs_precision:.4f}")
print(f"TVS Recall: {tvs_recall:.4f}")
print(f"TVS F1: {tvs_f1:.4f}")
print(f"TVS Time: {tvs_time:.2f} seconds")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Get the trained RandomForest model
rf_model = cvModel.bestModel.stages[-1]

# Extract feature importances
importances = rf_model.featureImportances.toArray()

# Get metadata from the predictions DataFrame
metadata = cv_predictions.schema["features"].metadata["ml_attr"]["attrs"]

# Rebuild feature name list from metadata
original_feature_names = []
for attr_type in ["binary", "numeric"]:
    if attr_type in metadata:
        original_feature_names += [attr["name"] for attr in metadata[attr_type]]

# Build mapping for scaled features
scaled_feature_map = {f"scaled_features_{i}": name for i, name in enumerate(numeric_features)}

# Rename all features
renamed_features = []
for name, score in zip(original_feature_names, importances):
    # Scaled numeric feature: scaled_features_#
    if name in scaled_feature_map:
        readable_name = scaled_feature_map[name]
    # One-hot encoded fields (categorical)
    elif name.startswith("dealer_zip_vec_"):
        readable_name = f"dealer_zip = {name.replace('dealer_zip_vec_', '')}"
    elif name.startswith("make_name_vec_"):
        readable_name = f"make_name = {name.replace('make_name_vec_', '')}"
    elif name.startswith("fuel_type_vec_"):
        readable_name = f"fuel_type = {name.replace('fuel_type_vec_', '')}"
    elif name.startswith("transmission_vec_"):
        readable_name = f"transmission = {name.replace('transmission_vec_', '')}"
    elif name.startswith("body_type_vec_"):
        readable_name = f"body_type = {name.replace('body_type_vec_', '')}"
    elif name.startswith("model_name_vec_"):
        readable_name = f"model_name = {name.replace('model_name_vec_', '')}"
    elif name.startswith("exterior_color_vec_"):
        readable_name = f"exterior_color = {name.replace('exterior_color_vec_', '')}"
    elif name.startswith("interior_color_vec_"):
        readable_name = f"interior_color = {name.replace('interior_color_vec_', '')}"
    elif name.startswith("franchise_make_vec_"):
        readable_name = f"franchise_make = {name.replace('franchise_make_vec_', '')}"
    elif name.startswith("wheel_system_vec_"):
        readable_name = f"wheel_system = {name.replace('wheel_system_vec_', '')}"
    else:
        readable_name = name

    renamed_features.append((readable_name, score))

# Sort and limit to top 10
top_features = sorted(renamed_features, key=lambda x: x[1], reverse=True)[:20]

# Print result
print("Top 10 Feature Importances (Readable Names):")
for name, score in top_features:
    print(f"{name}: {score:.4f}")

"""%pyspark

"""
